# OmniGen2 文本生成图像工作流

## 概述
使用 OmniGen2 模型将文本描述转换为高质量图像的工作流。

## 工作流特点
- **模型**: OmniGen2 FP16 优化版本
- **CLIP模型**: Qwen 2.5 VL FP16
- **VAE模型**: ae.safetensors
- **分辨率**: 1024x1024
- **采样器**: Euler
- **步数**: 20步

## 主要参数
- **正向提示词**: 描述想要生成的图像内容
- **负向提示词**: 描述不想要出现的内容（如模糊、低质量、扭曲等）
- **CFG强度**: 
  - 条件1: 5
  - 条件2负向: 2
- **噪声种子**: 可自定义或随机生成

## 节点说明
1. **CLIP加载器**: 加载 Qwen 2.5 VL 模型进行文本编码
2. **UNet加载器**: 加载 OmniGen2 主模型
3. **VAE加载器**: 加载 VAE 用于图像解码
4. **文本编码**: 处理正向和负向提示词
5. **双CFG引导器**: 使用双条件引导提高生成质量
6. **自定义采样器**: 执行高级采样过程
7. **VAE解码**: 将潜在空间转换为图像
8. **保存图像**: 输出最终生成的图像

## 使用示例
```python
params = {
    "positive_prompt": "一只戴着皇冠的猫懒洋洋地躺在天鹅绒王座上，皇家氛围，奢华的织物纹理，威严的姿势，细致的毛发，华丽的皇冠，戏剧性的灯光",
    "negative_prompt": "模糊，低质量，扭曲，丑陋，解剖错误，变形，画得不好",
    "width": 1024,
    "height": 1024,
    "steps": 20,
    "seed": 1082931635154736
}
```

## 输出
- 生成的图像将保存在 ComfyUI 输出目录中
- 文件名前缀: ComfyUI